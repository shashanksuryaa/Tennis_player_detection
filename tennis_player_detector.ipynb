{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5929769-e9f4-4898-bdd9-884e705291a8",
   "metadata": {},
   "source": [
    "# Tennis Player Tracking with Court Verification\n",
    "\n",
    "This Jupyter Notebook implements a system for detecting and tracking tennis players in a video, estimating the distance they cover, and verifying if the current view shows a valid tennis court.\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "This section installs the necessary libraries and imports them into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29774df6-19b1-483b-befe-ac35e638c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.3.146)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: deep_sort_realtime in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (70.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "## 1. Setup and Imports\n",
    "!pip install ultralytics opencv-python deep_sort_realtime pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6332504f-1f1a-4f32-9e7c-2efe926c37e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeep_sort_realtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepsort_tracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepSort\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structural_similarity \u001b[38;5;28;01mas\u001b[39;00m ssim\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from google.colab.patches import cv2_imshow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e927a-fe83-4daf-810e-e055e51e4c32",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Define various parameters for video paths, model selection, and spatial conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5055b49d-a2cc-4489-80a3-284834f3bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "VIDEO_PATH = '/content/tennis.mp4' # Update this path to your video file\n",
    "OUTPUT_PATH = 'output_annotated.mp4'\n",
    "YOLO_MODEL = 'yolov8n.pt' # Or 'yolov8m.pt', 'yolov8l.pt', etc.\n",
    "PIXELS_PER_COURT_WIDTH = 720 # Reference pixel width of the court at a known perspective\n",
    "COURT_WIDTH_METERS = 8.23 # Standard tennis court width\n",
    "PIXEL_TO_METER = COURT_WIDTH_METERS / PIXELS_PER_COURT_WIDTH # Conversion factor\n",
    "MIN_FRAMES_FOR_PLAYER = 20 # Minimum frames for a track to be considered a player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ecdea5-667d-466c-a0a3-b1ce9e8c7d12",
   "metadata": {},
   "source": [
    "## 3. Court Corner Reference \n",
    "\n",
    "Manually measured corner coordinates from the first frame. This section is for reference and is not actively used in the current tracking logic, but can be useful for court transformation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90e3906-8611-469d-968f-3b3f66a34380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Court Corner Reference (manually measured from first frame) ===\n",
    "court_corners_ref = np.array([\n",
    "    [100, 200],    # top-left\n",
    "    [1180, 200],   # top-right\n",
    "    [1180, 620],   # bottom-right\n",
    "    [100, 620]     # bottom-left\n",
    "], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1d0bc-366e-41e9-9224-dcc7716b4102",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Define utility functions for calculations, drawing, and court geometry analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2b4b3f-3b4e-4a52-af22-8edbd353df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper Functions ===\n",
    "def euclidean(p1, p2):\n",
    "    \"\"\"Calculates the Euclidean distance between two points.\"\"\"\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))\n",
    "\n",
    "def draw_text(frame, text, pos, font_scale=0.6, thickness=1, color=(255, 255, 255), bg=(0, 0, 0)):\n",
    "    \"\"\"Draws text on a video frame with an optional background.\"\"\"\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "    x, y = pos\n",
    "    cv2.rectangle(frame, (x, y - th - 4), (x + tw + 4, y + 4), bg, -1)\n",
    "    cv2.putText(frame, text, (x + 2, y - 2), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "\n",
    "def is_valid_court_geometry(frame, min_lines=5):\n",
    "    \"\"\"\n",
    "    Analyzes a frame to check for characteristics of a tennis court geometry\n",
    "    by detecting horizontal and vertical lines.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Use HoughLinesP to detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxGap=20)\n",
    "    if lines is None:\n",
    "        return False\n",
    "\n",
    "    vertical = 0\n",
    "    horizontal = 0\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        # Calculate angle of the line\n",
    "        angle = np.abs(np.arctan2(y2 - y1, x2 - x1))\n",
    "        # Classify lines as horizontal or vertical based on angle\n",
    "        if angle < np.pi / 12:      # approximately horizontal (within 15 degrees)\n",
    "            horizontal += 1\n",
    "        elif angle > np.pi / 3:     # approximately vertical (greater than 60 degrees)\n",
    "            vertical += 1\n",
    "\n",
    "    # Return True if sufficient horizontal and vertical lines are found\n",
    "    return horizontal >= min_lines and vertical >= min_lines\n",
    "\n",
    "def is_game_view(original_frame, current_frame):\n",
    "    \"\"\"Determines if the current frame is a valid game view based on court geometry.\"\"\"\n",
    "    # Currently relies solely on current frame geometry analysis\n",
    "    return is_valid_court_geometry(current_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38ef4b-9b1a-4db2-b1c1-a73bede7834c",
   "metadata": {},
   "source": [
    "## 5. Initialization\n",
    "\n",
    "Initialize the YOLO model, Deep SORT tracker, video capture, and video writer. Also, set up data structures for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3360e3-7c1b-4a0f-83ec-9a5dcf78eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video file /content/tennis.mp4\n",
      "Error: Could not read first frame.\n"
     ]
    }
   ],
   "source": [
    "# === Initialization ===\n",
    "model = YOLO(YOLO_MODEL) # Load the YOLO model\n",
    "tracker = DeepSort(max_age=30) # Initialize Deep SORT tracker\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH) # Open the video file\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {VIDEO_PATH}\")\n",
    "    exit() # Exit if video cannot be opened\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Or 'XVID', 'MJPG' depending on desired output format\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "# Data structures to store tracking information\n",
    "positions = defaultdict(list) # Stores historical (x, y) positions for each track ID\n",
    "distances = defaultdict(float) # Stores accumulated distance for each track ID\n",
    "player_labels = {} # Stores assigned labels ('Player A', 'Player B') for track IDs\n",
    "scene_active = True # Flag to indicate if the current scene is a valid game view\n",
    "\n",
    "# Read the first frame as a reference (currently used only by is_game_view signature)\n",
    "ret, original_scene = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Could not read first frame.\")\n",
    "    cap.release()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64b57b-e500-47ca-a119-9801a7d3a75b",
   "metadata": {},
   "source": [
    "## 6. Main Video Processing Loop\n",
    "\n",
    "Iterate through video frames, perform object detection and tracking, calculate distances, and annotate the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be431e17-8d52-4717-90d3-11b90dffd7f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Main Loop ===\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      3\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "# === Main Loop ===\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video or error reading frame.\")\n",
    "        break # Break the loop if no frame is read\n",
    "\n",
    "    # Check if the current frame represents a valid game view\n",
    "    is_valid = is_game_view(original_scene, frame)\n",
    "\n",
    "    if not is_valid:\n",
    "        # If not a valid game angle, display a message and pause tracking logic\n",
    "        draw_text(frame, \"NON-GAME ANGLE - PAUSED\", (10, 30), font_scale=0.7, color=(0, 0, 255), bg=(255, 255, 255))\n",
    "        scene_active = False\n",
    "        out.write(frame) # Still write the frame to the output\n",
    "        cv2_imshow(frame) # Display the frame (especially for Colab)\n",
    "        # Check for key press (e.g., 'q' to quit)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue # Skip tracking logic for this frame\n",
    "\n",
    "    # If transitioning from an inactive scene to an active one, reset tracking data\n",
    "    if not scene_active:\n",
    "        print(\"[INFO] Returning to game view - Resetting tracker.\")\n",
    "        tracker = DeepSort(max_age=30) # Re-initialize tracker\n",
    "        positions.clear() # Clear stored positions\n",
    "        distances.clear() # Clear accumulated distances\n",
    "        player_labels.clear() # Clear player labels\n",
    "        scene_active = True\n",
    "\n",
    "    # Perform object detection using YOLO\n",
    "    results = model(frame)[0]\n",
    "    detections = []\n",
    "    # Filter detections to include only 'person' with high confidence\n",
    "    for r in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = r\n",
    "        # Class ID 0 is typically 'person' in COCO dataset\n",
    "        if int(cls) == 0 and conf > 0.5:\n",
    "            # Format detection for Deep SORT: (x, y, w, h), confidence, class_name\n",
    "            detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'player'))\n",
    "\n",
    "    # Update the Deep SORT tracker with current detections\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    y_centers = {} # To store y-coordinates for player labeling\n",
    "\n",
    "    # Process each confirmed track\n",
    "    for track in tracks:\n",
    "        # Only consider confirmed tracks (seen for enough frames)\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id # Get the unique ID for this track\n",
    "        l, t, r, b = track.to_ltrb() # Get the bounding box in (left, top, right, bottom) format\n",
    "        cx, cy = int((l + r) / 2), int((t + b) / 2) # Calculate the center coordinates\n",
    "\n",
    "        # Store the current position\n",
    "        positions[track_id].append((cx, cy))\n",
    "\n",
    "        # Only start calculating distance and labeling after minimum frames\n",
    "        if len(positions[track_id]) < MIN_FRAMES_FOR_PLAYER:\n",
    "            continue\n",
    "\n",
    "        # Calculate and accumulate distance if there's a previous position\n",
    "        if len(positions[track_id]) > 1:\n",
    "            d_pix = euclidean(positions[track_id][-1], positions[track_id][-2]) # Distance in pixels between last two points\n",
    "            distances[track_id] += d_pix * PIXEL_TO_METER # Convert to meters and add to total\n",
    "\n",
    "        y_centers[track_id] = cy # Store y-center for labeling\n",
    "\n",
    "        # Draw bounding box and trajectory on the frame\n",
    "        cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2) # Green rectangle\n",
    "        for i in range(1, len(positions[track_id])):\n",
    "            cv2.line(frame, positions[track_id][i - 1], positions[track_id][i], (0, 0, 255), 2) # Red trajectory line\n",
    "\n",
    "    # Assign Player A/B labels based on vertical position if at least two players are tracked\n",
    "    if len(y_centers) >= 2:\n",
    "        # Sort track IDs by their y-center (smaller y is higher on the screen)\n",
    "        sorted_ids = sorted(y_centers.items(), key=lambda x: x[1])\n",
    "        player_labels[sorted_ids[0][0]] = \"Player A\" # Player A is higher\n",
    "        player_labels[sorted_ids[1][0]] = \"Player B\" # Player B is lower\n",
    "\n",
    "    # Draw player labels and distances on the frame\n",
    "    y_offset = 30\n",
    "    for tid, label in player_labels.items():\n",
    "        dist = distances[tid] # Get total distance for this player\n",
    "        # Draw label and total distance in the top-left corner\n",
    "        draw_text(frame, f\"{label}: {dist:.2f} m\", (10, y_offset))\n",
    "        y_offset += 30 # Move down for the next label\n",
    "\n",
    "        # Draw label, ID, and distance near the player's bounding box\n",
    "        if tid in positions and positions[tid]: # Ensure track exists and has positions\n",
    "             draw_text(frame, f\"{label} (ID {tid}) | {dist:.2f} m\", (positions[tid][-1][0] + 10, positions[tid][-1][1] - 10))\n",
    "\n",
    "\n",
    "    # Write the annotated frame to the output video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2_imshow(frame) # For Colab compatibility (replace with cv2.imshow for local execution)\n",
    "\n",
    "    # Check for key press (e.g., 'q' to quit)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# === Cleanup ===\n",
    "print(\"\\n[INFO] Processing finished.\")\n",
    "cap.release() # Release the video capture object\n",
    "out.release() # Release the video writer object\n",
    "cv2.destroyAllWindows() # Close any OpenCV windows\n",
    "\n",
    "# === Final Output ===\n",
    "print(\"\\n[INFO] Final Distances:\")\n",
    "for tid, label in player_labels.items():\n",
    "    # Ensure the track ID still exists in distances (might not if tracking was reset)\n",
    "    if tid in distances:\n",
    "        print(f\"{label} (ID {tid}): {distances[tid]:.2f} meters\")\n",
    "    else:\n",
    "        print(f\"{label} (ID {tid}): Data unavailable (tracking reset).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304695a3-4d7b-489b-81ee-b8e661e85766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
